{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1 Tasks 10-12: Clustering Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Story:_ You are a space scavenger exploring the origin of the most important invention in the world: the fidget spinner. You just arrived on the deserted planet and your AI buddy, Bubbles, has “imaged some items she found in a garbage heap” and collected some data for you. You look at the data and it seems like you might have found an ancient language!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/digits.csv',header = None).values[:, 1:]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 10:__ Run the code below to test your k-means implementation by clustering the alien character data using k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK 10 here\n",
    "from algorithms.kmeans import kmeans\n",
    "NUM_CLUSTERS = 5\n",
    "cluster_centers = kmeans(data, NUM_CLUSTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do your k-means clusters look like? How many clusters are there in the dataset? **Run the provided code below to visually check the accuracy of your k-means models.**\n",
    "\n",
    "If you're k-means implementation works, you're result will look something like this.\n",
    "![image.png](images/five-digits.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task 10 Continued. Run this code to visualize your cluster centers\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, NUM_CLUSTERS, figsize=(8, 3))\n",
    "unflattened_centers = np.array(cluster_centers).reshape(NUM_CLUSTERS, 8, 8)\n",
    "for axi, center in zip(ax.flat, unflattened_centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f kmeans kmeans(data, NUM_CLUSTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing k-means\n",
    "\n",
    "When we evaluate machine learning models such as k-means, the main factors we look to optimize include model accuracy, model interpretability, memory footprint, and execution time. In these last parts of the assignment, we will be looking at how to improve your model’s training time: the amount of time it takes for k-means to find the clusters via improving the speed that it computes centroids.\n",
    "\n",
    "The next two tasks require you to create vectorized and parallelized versions of your k-means code. Put these versions of your code in `algorithms/kmeansvec.py` and `algorithms/kmeanspar.py`. \n",
    "\n",
    "\n",
    "### Vectorizing k-means\n",
    "For numerical processing in Python many scientists rely on the [NumPy package](http://www.numpy.org/).  This package is built on optimized C code, it is often much faster to use it rather than plain Python. For example, a Python for-loop executes many additional instructions to ensure that it can correctly iterate over a list containing multiple data types.\n",
    "\n",
    "However, to take advantage of NumPy optimizations you need to “vectorize” your code. This means instead of applying functions/operations element-wise; we want to think of the function inputs as mathematical vectors. Here are some examples of vectorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Initialize the NumPy arrays\n",
    "u = np.array([1, 2, 3])\n",
    "v = np.array([1, 2, 4])\n",
    "\n",
    "# Vector sum\n",
    "print('Summing in plain python:', [u[i] + v[i] for i in range(len(u))])\n",
    "print('Summing with NumPy:', u + v)\n",
    "\n",
    "# Dot product\n",
    "print('Plain python dot product:', sum([u[i] * v[i] for i in range(len(u))]))\n",
    "print('Numpy dot product:', np.dot(u, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to avoid element-wise operations and work on whole vectors and matrices instead.\n",
    "\n",
    "__Task 11:__ Make copy of your ```kmeans.py``` code and use vectorization to speed up your k-means code in `algorithms/kmeansvec.py`. Your improved k-means program should not contain nested for-loops. Verify its correctness by its performance on your handwritten digits dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from algorithms.kmeansvec import kmeans_vec\n",
    "NUM_CLUSTERS = 5\n",
    "cluster_centers = kmeans_vec(data, NUM_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#cluster_centers = model.cluster_centers_\n",
    "\n",
    "fig, ax = plt.subplots(1, NUM_CLUSTERS, figsize=(8, 3))\n",
    "unflattened_centers = np.array(cluster_centers).reshape(NUM_CLUSTERS, 8, 8)\n",
    "for axi, center in zip(ax.flat, unflattened_centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f kmeans_vec kmeans_vec(data, NUM_CLUSTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing k-means\n",
    "Modern computers generally contain multiple independent processing units called cores.\n",
    "\n",
    "When we can split the computations between cores, we may possibly speed up a program. For merge sort, we can initially partition the data into halves and send the left half to core A and the right half to core B. Then each core can sort a half at the same time. Once each half of the data has been sorted, it then needs to be merged. Parallelizing with just one division on to two cores will result in an almost twofold increase in speed.  \n",
    "\n",
    "We can use the multiprocessing module in Python to take advantage of processing over two or more cores.\n",
    "\n",
    "Below is an example of how one can parallelize merge sort using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "from algorithms.mergesort import merge_sort, merge\n",
    "\n",
    "\n",
    "def parallel_merge_sort(alist):\n",
    "    # Sets up 2 Python processes\n",
    "    p = Pool(2)\n",
    "    \n",
    "    mid = len(alist) // 2\n",
    "    \n",
    "    # Assign tasks each process \n",
    "    sorted_left, sorted_right = p.map(merge_sort, [alist[:mid], alist[mid:]])  \n",
    "    return merge(sorted_left, sorted_right)\n",
    "\n",
    "assert parallel_merge_sort([]) == []\n",
    "assert parallel_merge_sort([10]) == [10]\n",
    "assert parallel_merge_sort([2, 1, 3]) == [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 12:__ In this task you make a copy of your ```kmeansvec.py``` code and use parallelization to speed up your k-means code in `algorithms/kmeanspar.py` by parallelling the ```assign_step()``` function to make use of the a pool object from the multiprocessing module. Test your code by visualizing the output using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.kmeanspar import kmeans_par\n",
    "NUM_CLUSTERS = 5\n",
    "cluster_centers = kmeans_par(data, NUM_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, NUM_CLUSTERS, figsize=(8, 3))\n",
    "unflattened_centers = np.array(cluster_centers).reshape(NUM_CLUSTERS, 8, 8)\n",
    "for axi, center in zip(ax.flat, unflattened_centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 13:__ Use timing or profiling to examine and compare the performance of your k-means implementations.  See the final part of lab1a for more information on lprun. Here is another great resource \n",
    "\n",
    "http://pynash.org/2013/03/06/timing-and-profiling/\n",
    "\n",
    "Place your code below.  Create any additional functions you need achieve this and include them with you hand-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Submission\n",
    "When you are ready to submit, your local repository should have the following files in it:\n",
    "```\n",
    "algorithms/\n",
    "\ttests/\n",
    "\t\t__init__.py\n",
    "\t\ttest_algorithms.py\n",
    "\t__init__.py\n",
    "\tbubblesort.py\n",
    "\tmergesort.py\n",
    "\tkmeans.py\n",
    "    kmeansvec.py\n",
    "    kmeanspar.py\n",
    "preparation/\n",
    "\tloading.py\n",
    "clustering_digits.ipynb\n",
    "timing_sorts.ipynb\n",
    "```\n",
    "Commit your changes and then push your repository to your private GitHub repository.\n",
    "\n",
    "\n",
    "References\n",
    "Parallelizable sorts: http://www.dcc.fc.up.pt/~fds/aulas/PPD/1112/sorting.pdf\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
